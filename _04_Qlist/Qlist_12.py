from pyspark.sql import SparkSession
from pyspark.sql.functions import sum, collect_list, struct

spark = SparkSession.builder.appName('test_12').getOrCreate()
spark.conf.set("spark.sql.repl.eagerEval.enabled", True)  # å¯ç”¨ eager evaluation
spark.conf.set("spark.sql.repl.eagerEval.truncate", 100)  #è®¾ç½® DataFrame çš„åˆ—å®½
data = [
    ("john", "tomato", 2),
    ("ğš‹ğš’ğš•ğš•", "ğšŠğš™ğš™ğš•ğš", 2),
    ("john", "ğš‹ğšŠğš—ğšŠğš—ğšŠ", 2),
    ("john", "tomato", 3),
    ("ğš‹ğš’ğš•ğš•", "ğšğšŠğšŒğš˜", 2),
    ("ğš‹ğš’ğš•ğš•", "ğšŠğš™ğš™ğš•ğš", 2)
]
schema = "name string,item string,weight int"
df = spark.createDataFrame(data, schema)

df_gb = df.groupBy('name','item').agg(sum(df.weight).alias('sum_weight'))
df_final = df_gb.groupBy('name').agg(collect_list(struct('item','sum_weight')).alias('items'))

df_final.show()